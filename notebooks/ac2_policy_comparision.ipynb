{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d19322-3809-497a-a168-c2b15ed98f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "import json\n",
    "import xmltodict\n",
    "\n",
    "import stable_baselines3\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68c3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FOLDER = '../evaluations'\n",
    "META_FOLDER = \"../meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c22eb-945c-4021-a4c8-023d1ee06822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A2C models experiment 1: High and low traffic scenarios\n",
    "MODEL_HIGH = \"a2c_custom-2way-single-intersection-high_100000_stepsintelli_light_reward_delay_3_waiting_time_3_light_switches_2\"\n",
    "MODEL_LOW = \"a2c_custom-2way-single-intersection-low_100000_stepsintelli_light_reward_delay_3_waiting_time_3_light_switches_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00588c02-be7e-442c-b394-3bd761c5d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2C models experiment 2: Broken traffic light scenario\n",
    "MODEL_HIGH = \"a2c_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1\"  # \"a2c_custom-2way-single-intersection-high_100000_steps\"\n",
    "MODEL_LOW = \"a2c_broken_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1\" # \"a2c_custom-2way-single-intersection-low_100000_steps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d62e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d663a4-8e0e-40fb-adf2-abce33242d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(obs):\n",
    "    obs = np.asarray(obs)\n",
    "    obs = torch.from_numpy(obs).float()\n",
    "    return obs\n",
    "\n",
    "def load_data(prefix, traffic):\n",
    "    with open(f\"{META_FOLDER}/{traffic}.json\") as f:\n",
    "        meta_data = json.load(f)\n",
    "    def translate_action(action):\n",
    "        # TODO: add fix in evaluate script\n",
    "        if action.startswith(\"[\"):\n",
    "            action = action.replace(\"  \", \" \").replace(\"[ \", \"[\").replace(\" \", \", \")\n",
    "        action = ast.literal_eval(action)\n",
    "        tf_ids = list(ast.literal_eval(df_single_episode.obs.to_list()[0]).keys())\n",
    "        n_splits = len(action)\n",
    "        if isinstance(action, list):\n",
    "            if len(action) == 1:\n",
    "                action_dict = {tf_ids[0]: action[0]}  # TODO: rename traffic signal in single traffic light scenario\n",
    "            else:\n",
    "                action_dict = {tf_ids[i]: a \n",
    "                              for i, a in enumerate(action)}\n",
    "        \n",
    "        green = []\n",
    "        for tf_id, p in action_dict.items():\n",
    "#             print(tf_id, p , meta_data[tf_id][\"phases\"])\n",
    "            green_tf = f\"{tf_id}:\"\n",
    "            green_tf += \", \".join(meta_data[tf_id][\"phases\"][str(p)][\"lanes_green\"])\n",
    "            green.append(green_tf)\n",
    "        return \"; \".join(green)\n",
    "    print(\"Loading\", f'{EVAL_FOLDER}/{prefix}_{traffic}_1_episode.csv')\n",
    "    df_single_episode = pd.read_csv(f'{EVAL_FOLDER}/{prefix}_{traffic}_1_episode.csv')\n",
    "    df_single_episode = df_single_episode.set_index('step')\n",
    "    df_single_episode = df_single_episode.drop(columns=['cumulative_reward'])\n",
    "    df_single_episode[\"translated_action\"]= df_single_episode['action'].apply(\n",
    "        lambda x: translate_action(x)\n",
    "    )\n",
    "    n_splits = len(df_single_episode.translated_action.to_list()[0].split(\"; \"))\n",
    "    df_single_episode[[f\"translated_action_tf_{i}\"\n",
    "                      for i in range(n_splits)]] = df_single_episode['translated_action'].str.split('; ', expand=True)\n",
    "    \n",
    "    \n",
    "    df_multiple_episodes = pd.read_csv(f'{EVAL_FOLDER}/{prefix}_{traffic}_100_episode.csv')\n",
    "    df_multiple_episodes = df_multiple_episodes.set_index('episode')\n",
    "    # df_multiple_episodes = df_multiple_episodes.drop(columns=['cumulative_reward'])\n",
    "    # df_multiple_episodes = None\n",
    "    return df_single_episode, df_multiple_episodes\n",
    "\n",
    "def compare_datasets(datasets):\n",
    "    results = []\n",
    "    for name, df in datasets:\n",
    "        data = {\n",
    "            'dataset': name,\n",
    "#             'avg_cumulative_reward': np.mean(df.cumulative_reward.to_list()),\n",
    "            # 'mean_waiting_time': np.mean(df.mean_waiting_time.to_list()),\n",
    "            \n",
    "            'avg_travel_time': np.mean(df.avg_travel_time.to_list()),\n",
    "            'avg_time_loss': np.mean(df.avg_time_loss.to_list()),\n",
    "            'avg_waiting_time': np.mean(df.avg_waiting_time.to_list()),\n",
    "\n",
    "            'collisions': np.mean(df.collisions.to_list()),\n",
    "            'emergency_braking': np.mean(df.emergency_braking.to_list()),\n",
    "            'emergency_stops': np.mean(df.emergency_stops.to_list()),\n",
    "\n",
    "#             'mean_speed': np.mean(df.mean_speed.to_list()),\n",
    "            'mean_lane_density': np.mean(df.mean_lane_density.to_list()),\n",
    "            'mean_queue': np.mean(df.mean_queue_length.to_list()),\n",
    "\n",
    "        }\n",
    "        results.append(data)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix naming\n",
    "prefix = [MODEL_LOW, MODEL_HIGH]\n",
    "base_traffic = \"custom-2way-single-intersection\"\n",
    "traffic_scenario1 = f\"{base_traffic}-low\"\n",
    "datasets1 = [\n",
    "    (\n",
    "        \"a=\" + \"_\".join(p.split(\"_\")[:2]).replace(base_traffic, \"\") + f\";t={traffic_scenario1}\",\n",
    "        load_data(p, traffic_scenario1)[1]\n",
    "    ) for p in prefix\n",
    "]\n",
    "traffic_scenario2 = f\"{base_traffic}-high\"\n",
    "datasets2 = [\n",
    "    (\n",
    "        \"a=\" +\"_\".join(p.split(\"_\")[:2]).replace(base_traffic, \"\")+ f\";t={traffic_scenario2}\",\n",
    "        load_data(p, traffic_scenario2)[1]\n",
    "    ) for p in prefix\n",
    "]\n",
    "\n",
    "datasets = datasets1 + datasets2\n",
    "compare_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef0d9d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../evaluations/a2c_broken_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1_3x3grid-3lanes2_1_episode.csv\n",
      "Loading ../evaluations/a2c_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1_3x3grid-3lanes2_1_episode.csv\n",
      "Loading ../evaluations/a2c_broken_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1_broken_3x3grid-3lanes2_1_episode.csv\n",
      "Loading ../evaluations/a2c_3x3grid-3lanes2_250000_stepsintelli_light_prcol_rewarddelay_3_waiting_time_3_light_switches_2_out_lanes_availability_1_broken_3x3grid-3lanes2_1_episode.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>avg_travel_time</th>\n",
       "      <th>avg_time_loss</th>\n",
       "      <th>avg_waiting_time</th>\n",
       "      <th>collisions</th>\n",
       "      <th>emergency_braking</th>\n",
       "      <th>emergency_stops</th>\n",
       "      <th>mean_lane_density</th>\n",
       "      <th>mean_queue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a=a2c_broken;t=3x3grid-3lanes2_broken</td>\n",
       "      <td>334.292226</td>\n",
       "      <td>273.1253</td>\n",
       "      <td>248.9308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.277063</td>\n",
       "      <td>48.709917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a=a2c_;t=3x3grid-3lanes2_3x3grid-3lanes2</td>\n",
       "      <td>272.277348</td>\n",
       "      <td>210.9422</td>\n",
       "      <td>187.8273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.577341</td>\n",
       "      <td>36.531486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a=a2c_broken;t=3x3grid-3lanes2_broken</td>\n",
       "      <td>260.358614</td>\n",
       "      <td>204.4458</td>\n",
       "      <td>183.6750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.775956</td>\n",
       "      <td>130.939083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a=a2c_;t=3x3grid-3lanes2_3x3grid-3lanes2</td>\n",
       "      <td>273.436138</td>\n",
       "      <td>217.5477</td>\n",
       "      <td>196.6524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.891745</td>\n",
       "      <td>133.004819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    dataset  avg_travel_time  avg_time_loss  \\\n",
       "0     a=a2c_broken;t=3x3grid-3lanes2_broken       334.292226       273.1253   \n",
       "1  a=a2c_;t=3x3grid-3lanes2_3x3grid-3lanes2       272.277348       210.9422   \n",
       "2     a=a2c_broken;t=3x3grid-3lanes2_broken       260.358614       204.4458   \n",
       "3  a=a2c_;t=3x3grid-3lanes2_3x3grid-3lanes2       273.436138       217.5477   \n",
       "\n",
       "   avg_waiting_time  collisions  emergency_braking  emergency_stops  \\\n",
       "0          248.9308         0.0               0.01             0.01   \n",
       "1          187.8273         0.0               0.02             0.01   \n",
       "2          183.6750         0.0               0.00             0.00   \n",
       "3          196.6524         0.0               0.00             0.00   \n",
       "\n",
       "   mean_lane_density  mean_queue  \n",
       "0           3.277063   48.709917  \n",
       "1           2.577341   36.531486  \n",
       "2           7.775956  130.939083  \n",
       "3           7.891745  133.004819  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_scenario = '3x3grid-3lanes2'\n",
    "prefix = [MODEL_LOW, MODEL_HIGH, f\"{MODEL_LOW}_broken\", f\"{MODEL_HIGH}_broken\"]\n",
    "datasets = [(\n",
    "    \"a=\" +\"_\".join(p.split(\"_\")[:2]).replace(traffic_scenario, \"\")+ f\";t={traffic_scenario}_{p.split('_')[1]}\",\n",
    "        load_data(p, traffic_scenario)[1]\n",
    "    ) for p in prefix]\n",
    "compare_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188d153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984cbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5472fad-c488-45bb-92e3-b73fc2aafb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26dba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e8435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_traffic = \"custom-2way-single-intersection\"\n",
    "traffic = f\"{base_traffic}-high\"\n",
    "df_single_episode_low, _ = load_data(MODEL_LOW, traffic)\n",
    "df_single_episode_high, _ = load_data(MODEL_HIGH, traffic)\n",
    "\n",
    "n_splits = len(df_single_episode_high.translated_action.to_list()[0].split(\"; \"))\n",
    "for i in range(n_splits):\n",
    "    column = f\"translated_action_tf_{i}\"\n",
    "    print(\"Results\", traffic, column)\n",
    "    \n",
    "    grouped = pd.DataFrame({f'{column}_model_low': df_single_episode_low[column],\n",
    "                            f'{column}_model_high': df_single_episode_high[column]}) \n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_low\"], color=\"blue\", label=\"model_low\")\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_high\"], color=\"orange\", label=\"model_high\")\n",
    "\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"action\")\n",
    "    plt.title(f\"Actions Over Time for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(grouped[[f'{column}_model_low', f'{column}_model_high']], label=[\"model_low\", \"model_high\"])\n",
    "    plt.xlabel(\"Action\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Action Distribution for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_traffic = \"custom-2way-single-intersection\"\n",
    "traffic = f\"{base_traffic}-low\"\n",
    "df_single_episode_low, _ = load_data(MODEL_LOW, traffic)\n",
    "df_single_episode_high, _ = load_data(MODEL_HIGH, traffic)\n",
    "\n",
    "n_splits = len(df_single_episode_high.translated_action.to_list()[0].split(\"; \"))\n",
    "for i in range(n_splits):\n",
    "    column = f\"translated_action_tf_{i}\"\n",
    "    print(\"Results\", traffic, column)\n",
    "    \n",
    "    grouped = pd.DataFrame({f'{column}_model_low': df_single_episode_low[column],\n",
    "                            f'{column}_model_high': df_single_episode_high[column]}) \n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_low\"], color=\"blue\", label=\"model_low\")\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_high\"], color=\"orange\", label=\"model_high\")\n",
    "\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"action\")\n",
    "    plt.title(f\"Actions Over Time for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(grouped[[f'{column}_model_low', f'{column}_model_high']], label=[\"model_low\", \"model_high\"])\n",
    "    plt.xlabel(\"Action\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Action Distribution for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4e9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = '3x3grid-3lanes2'\n",
    "df_single_episode, _ = load_data(f\"{MODEL_LOW}_broken\", traffic)\n",
    "n_splits = len(df_single_episode.translated_action.to_list()[0].split(\"; \"))\n",
    "for i in range(n_splits):\n",
    "    column = f\"translated_action_tf_{i}\"\n",
    "    print(\"Results\", MODEL_HIGH, traffic, column)\n",
    "\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.scatter(df_single_episode.index, df_single_episode[column], c=df_single_episode.option)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"action\")\n",
    "    plt.title(f\"Actions Over Time for {MODEL_HIGH} traffic signal {i}\")\n",
    "    plt.colorbar(label=\"Option ID\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df_single_episode, x=column, hue=\"option\", multiple=\"dodge\", palette=\"tab10\")\n",
    "    plt.xlabel(\"Action\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Action Distribution for {MODEL_HIGH} traffic signal {i}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cc252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traffic = '3x3grid-3lanes'\n",
    "df_single_episode, _ = load_data(f\"{MODEL_HIGH}_broken\", traffic)\n",
    "n_splits = len(df_single_episode.translated_action.to_list()[0].split(\"; \"))\n",
    "for i in range(n_splits):\n",
    "    column = f\"translated_action_tf_{i}\"\n",
    "    print(\"Results\", traffic, column)\n",
    "    \n",
    "    grouped = pd.DataFrame({f'{column}_model_low': df_single_episode_low[column],\n",
    "                            f'{column}_model_high': df_single_episode_high[column]}) \n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_low\"], color=\"blue\", label=\"model_low\")\n",
    "    plt.scatter(grouped.index, grouped[f\"{column}_model_high\"], color=\"orange\", label=\"model_high\")\n",
    "\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"action\")\n",
    "    plt.title(f\"Actions Over Time for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(grouped[[f'{column}_model_low', f'{column}_model_high']], label=[\"model_low\", \"model_high\"])\n",
    "    plt.xlabel(\"Action\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Action Distribution for {MODEL_LOW} traffic signal {i}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10bf7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f149342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315eec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3771bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_episode.action.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ad660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c7da8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traffic = \"custom-2way-single-intersection-high\"\n",
    "df_single_episode, _ = load_data(MODEL_LOW, traffic)\n",
    "print(\"Results\", MODEL_LOW, traffic)\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.scatter(df_single_episode.index, df_single_episode.translated_action, c=df_single_episode.option)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"action\")\n",
    "plt.title(\"Actions Over Time\")\n",
    "plt.colorbar(label=\"Option ID\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_single_episode, x=column, hue=\"option\", multiple=\"dodge\", palette=\"tab10\")\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Action Distribution Per Option\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = \"custom-2way-single-intersection-high\"\n",
    "df_single_episode, _ = load_data(MODEL_HIGH, traffic)\n",
    "print(\"Results\", MODEL_HIGH, traffic)\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.scatter(df_single_episode.index, df_single_episode.translated_action, c=df_single_episode.option)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"action\")\n",
    "plt.title(\"Actions Over Time\")\n",
    "plt.colorbar(label=\"Option ID\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_single_episode, x=\"translated_action\", hue=\"option\", multiple=\"dodge\", palette=\"tab10\")\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Action Distribution Per Option\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28e833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cb8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs(df, index, traffic):\n",
    "    total_observation = []\n",
    "    unnested_obs = {}\n",
    "    \n",
    "    with open(f\"./meta/{traffic}.json\") as f:\n",
    "        meta_data = json.load(f)\n",
    "    \n",
    "    for tf_id, observation_dict in json.loads(df.obs.to_list()[index]).items():        \n",
    "        # current_time = observation_dict[\"current_time\"]\n",
    "        phase_ids = observation_dict[\"current_phase_ids\"]\n",
    "        # phase_ids = observation_dict[\"hist_phase_ids\"]\n",
    "        # min_green = observation_dict[\"min_green\"]\n",
    "        # density = observation_dict[\"density\"]\n",
    "        queue = observation_dict[\"queue\"]\n",
    "        # queue_der = observation_dict[\"queue_der\"]\n",
    "        # average_speed = observation_dict[\"average_speed\"]\n",
    "        waiting_times = []\n",
    "        for waiting_time in observation_dict[\"waiting_times\"]:\n",
    "            if waiting_time:\n",
    "                waiting_times.append(np.max(waiting_time))\n",
    "            else:\n",
    "                waiting_times.append(0)\n",
    "        # observation = np.array(phase_ids + queue + queue_der + waiting_times + [average_speed], dtype=np.float32)\n",
    "        observation = np.array(phase_ids + queue + waiting_times, dtype=np.float32)\n",
    "        \n",
    "        # TODO: check if I can update the phase ids?\n",
    "        # TODO: double check queue_der\n",
    "        tf_meta_data = meta_data[tf_id]        \n",
    "        \n",
    "        total_observation.extend(observation)\n",
    "        for key, value in observation_dict.items():           \n",
    "            if isinstance(value, list):\n",
    "                for index, item in enumerate(value):\n",
    "                    suffix = index\n",
    "                    if key in [\"queue\"]:\n",
    "                        suffix = tf_meta_data[\"lanes\"][\"cleaned_incoming\"][str(index)]\n",
    "                    unnested_obs[f\"{tf_id}_{key}_{suffix}\"] = item\n",
    "            else:\n",
    "                unnested_obs[f\"{tf_id}_{key}\"] = value\n",
    "    total_observation = np.array(total_observation, dtype=np.float32)    \n",
    "\n",
    "\n",
    "    return total_observation, current_option, unnested_obs\n",
    "\n",
    "def __get_action_distribution(obs, policy_model):\n",
    "    \"\"\"Get the action distribution for the given state and option.\n",
    "\n",
    "    Args:\n",
    "        state: State to calculate the action distribution for.\n",
    "        model: Model to calculate the action distribution with.\n",
    "        option: Option to calculate the action distribution for.\n",
    "\n",
    "    Returns:\n",
    "        array: Numpy array with the action distribution.\n",
    "    \"\"\"\n",
    "    state = {}\n",
    "    for key, observation_dict in obs.items():\n",
    "        phase_ids = observation_dict[\"hist_phase_ids\"]\n",
    "        queue = observation_dict[\"queue\"]\n",
    "        queue_der = observation_dict[\"queue_der\"]\n",
    "        average_speed = observation_dict[\"average_speed\"]\n",
    "        waiting_times = []\n",
    "        for waiting_time in observation_dict[\"waiting_times\"]:\n",
    "            if waiting_time:\n",
    "                waiting_times.append(np.mean(waiting_time))\n",
    "            else:\n",
    "                waiting_times.append(0)\n",
    "        combined_obs = np.array(phase_ids + queue + queue_der + waiting_times + [average_speed], dtype=np.float32)\n",
    "        state[key] = torch.tensor([combined_obs], dtype=torch.float32, device=\"cuda\")\n",
    "    return policy_model.get_distribution(state).distribution[0].probs.cpu().detach().numpy()[0]\n",
    "\n",
    "\n",
    "def hellinger_distance(state, model_1, model_2) -> float:\n",
    "    \"\"\"Calculate the hellinger distance between the intra-option policies of the model\n",
    "    for the given state.\n",
    "    This as defined in the paper \"Disentangling Options with Hellinger Distance Regularizer\"\n",
    "\n",
    "    Args:\n",
    "        states: The states for which to calculate the hellinger distance.\n",
    "        model: The option critic model to calculate the distance for.\n",
    "\n",
    "    Returns:\n",
    "        float: Helling distance loss\n",
    "    \"\"\"\n",
    "    p_dist = __get_action_distribution(state, model_1.policy)\n",
    "    q_dist = __get_action_distribution(state, model_2.policy)\n",
    "    summation = np.sum((np.sqrt(p_dist) - np.sqrt(q_dist)) ** 2)\n",
    "    hd = math.sqrt(summation) / math.sqrt(2)\n",
    "    return hd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae568749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high = stable_baselines3.A2C.load(\n",
    "    f\"./models/{MODEL_HIGH}.zip\"\n",
    ")\n",
    "\n",
    "model_low = stable_baselines3.A2C.load(\n",
    "    f\"./models/{MODEL_LOW}.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fd5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traffic = \"custom-2way-single-intersection-high\"\n",
    "df_single_episode_high, _ = load_data(MODEL_HIGH, traffic)\n",
    "\n",
    "results = []\n",
    "distances = []\n",
    "for index in range(df_single_episode_high.shape[0]):\n",
    "    obs, current_option, unnested_dict = get_obs(df_single_episode_high, index, traffic)\n",
    "    results.append({\n",
    "        \"step\": index*5,\n",
    "        \"action_high\": model_high.predict({\"t\": obs})[0][0],\n",
    "        \"action_low\": model_low.predict({\"t\": obs})[0][0]\n",
    "    })\n",
    "    hd_distance = hellinger_distance(json.loads(df_single_episode_high.obs.to_list()[index]), model_low, model_high)\n",
    "    distances.append(hd_distance)\n",
    "    \n",
    "df_action_comparision = pd.DataFrame(results)\n",
    "# df_action_comparision = df_action_comparision.set_index('step')\n",
    "print(df_action_comparision.shape)\n",
    "print(\"equal\", df_action_comparision[df_action_comparision.action_high == df_action_comparision.action_low].shape[0])\n",
    "print(np.mean(distances), np.std(distances))\n",
    "print(np.max(distances), np.min(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = \"custom-2way-single-intersection-low\"\n",
    "df_single_episode_high, _ = load_data(MODEL_HIGH, traffic)\n",
    "\n",
    "results = []\n",
    "distances = []\n",
    "for index in range(df_single_episode_high.shape[0]):\n",
    "    obs, current_option, unnested_dict = get_obs(df_single_episode_high, index, traffic)\n",
    "    results.append({\n",
    "        \"step\": index*5,\n",
    "        \"action_high\": model_high.predict({\"t\": obs})[0][0],\n",
    "        \"action_low\": model_low.predict({\"t\": obs})[0][0]\n",
    "    })\n",
    "    hd_distance = hellinger_distance(json.loads(df_single_episode_high.obs.to_list()[index]), model_low, model_high)\n",
    "    distances.append(hd_distance)\n",
    "    \n",
    "df_action_comparision = pd.DataFrame(results)\n",
    "# df_action_comparision = df_action_comparision.set_index('step')\n",
    "print(df_action_comparision.shape)\n",
    "print(\"equal\", df_action_comparision[df_action_comparision.action_high == df_action_comparision.action_low].shape[0])\n",
    "print(np.mean(distances), np.std(distances))\n",
    "print(np.max(distances), np.min(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b159f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43a4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413ae3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc760f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7acdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "\n",
    "# Scatter plot for Column2\n",
    "plt.scatter(df_action_comparision['step'], df_action_comparision['action_high'], color='blue', label='action_high', alpha=0.7)\n",
    "\n",
    "# Scatter plot for Column3\n",
    "plt.scatter(df_action_comparision['step'], df_action_comparision['action_low'], color='red', label='action_low', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('actions')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_repeating_patterns(df, column, window_size):\n",
    "    \"\"\"\n",
    "    Find repeating sequences of length `window_size` in a given column of a DataFrame.\n",
    "    \"\"\"\n",
    "    patterns = defaultdict(list)\n",
    "    series = df[column].tolist()\n",
    "\n",
    "    # Store occurrences of each pattern\n",
    "    for i in range(len(series) - window_size + 1):\n",
    "        pattern = tuple(series[i : i + window_size])  # Convert slice to tuple (hashable)\n",
    "        patterns[pattern].append(i)  # Store start index of pattern\n",
    "\n",
    "    # Filter only repeating patterns\n",
    "    repeating_patterns = {k: len(v) for k, v in patterns.items() if len(v) > 1}\n",
    "    return repeating_patterns\n",
    "\n",
    "repeating_patterns_high = find_repeating_patterns(df_action_comparision, 'action_high', window_size=4)\n",
    "repeating_patterns_low = find_repeating_patterns(df_action_comparision, 'action_low', window_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665507d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repeating_high = pd.DataFrame([{\"cycle\": key, \"count\": value}\n",
    "                                 for key, value in repeating_patterns_high.items()])\n",
    "df_repeating_low = pd.DataFrame([{\"cycle\": key, \"count\": value}\n",
    "                                 for key, value in repeating_patterns_low.items()])\n",
    "df_repeating_comparision = df_repeating_high.merge(df_repeating_low, on=\"cycle\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489b805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_repeating_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb84386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67349735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b454867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _, row in df_single_episode.iterrows():\n",
    "    obs = [float(s.strip()) for s in row.obs.split(',')]\n",
    "    state = agent.get_state(to_tensor(obs))\n",
    "    option_distributions_dict = {}\n",
    "    for option in range(0, df_single_episode.option.max() + 1):\n",
    "        dist = get_action_dist(agent, state, option)[0]\n",
    "        for i, value in enumerate(dist):\n",
    "            if i not in option_distributions_dict:\n",
    "                option_distributions_dict[i] = {'action': i}\n",
    "            option_distributions_dict[i][f'prob_option_{option}'] = value        \n",
    "    results.append(option_distributions_dict)\n",
    "avg_dist = {key: {'action': key, 'prob_option_0': 0, 'prob_option_1': 0} for key in results[0].keys()}\n",
    "for item in results:\n",
    "    for key, value in item.items():\n",
    "        for option in range(n_options):\n",
    "            option_prob = f'prob_option_{option}'\n",
    "            avg_dist[key][option_prob] += value[option_prob]\n",
    "for _, value in avg_dist.items():\n",
    "    for option in range(n_options):\n",
    "        option_prob = f'prob_option_{option}'\n",
    "        value[option_prob] = value[option_prob] / len(results)\n",
    "df_avg_action_distributions = pd.DataFrame(list(avg_dist.values()))\n",
    "px.bar(\n",
    "    data_frame = df_avg_action_distributions,\n",
    "    x = \"action\",\n",
    "    y = [f'prob_option_{option}' for option in range(n_options)],\n",
    "    opacity = 0.9,\n",
    "    orientation = \"v\",\n",
    "    barmode = 'group',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41848d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeede02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _, row in df_single_episode.iterrows():\n",
    "    obs = [float(s.strip()) for s in row.obs.split(',')]\n",
    "    state = agent.get_state(to_tensor(obs))\n",
    "    option_distributions_dict = {}\n",
    "    for option in range(0, df_single_episode.option.max() + 1):\n",
    "        dist = get_action_dist(agent, state, option)[0]\n",
    "        for i, value in enumerate(dist):\n",
    "            if i not in option_distributions_dict:\n",
    "                option_distributions_dict[i] = {'action': i}\n",
    "            option_distributions_dict[i][f'prob_option_{option}'] = value        \n",
    "    results.append(option_distributions_dict)\n",
    "avg_dist = {key: {'action': key, 'prob_option_0': 0, 'prob_option_1': 0} for key in results[0].keys()}\n",
    "n_options = 2\n",
    "for item in results:\n",
    "    for key, value in item.items():\n",
    "        for option in range(n_options):\n",
    "            option_prob = f'prob_option_{option}'\n",
    "            avg_dist[key][option_prob] += value[option_prob]\n",
    "for _, value in avg_dist.items():\n",
    "    for option in range(n_options):\n",
    "        option_prob = f'prob_option_{option}'\n",
    "        value[option_prob] = value[option_prob] / len(results)\n",
    "df_avg_action_distributions = pd.DataFrame(list(avg_dist.values()))\n",
    "px.bar(\n",
    "    data_frame = df_avg_action_distributions,\n",
    "    x = \"action\",\n",
    "    y = [f'prob_option_{option}' for option in range(n_options)],\n",
    "    opacity = 0.9,\n",
    "    orientation = \"v\",\n",
    "    barmode = 'group',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f30e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ec938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03591d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a9b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_encoded = pd.get_dummies(df_single_episode[['action', 'option']], columns=['action', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_encoded.groupby('option').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6603bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca80d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703a940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7be3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a087f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b7836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27f279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad5f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b048fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e64718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4cf77-27c7-4625-9f8e-84a484a7cb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582622a-4f19-4b3f-9b09-092aff73d486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e79ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694d813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08bc1c-da3b-4ff1-ab81-017bfb5b5284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b148b9-be86-4e44-b3d5-173b950d7b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20330b30-0310-416a-ae01-29a9abed00c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae88b0-1be6-4b34-a94e-6b9814f4812e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3608c-8dda-4b42-b735-e82cb17c3ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef9a96-3a62-4def-9231-55e1213bd154",
   "metadata": {},
   "outputs": [],
   "source": [
    "lanes = ['n_t_0', 'n_t_1', 'e_t_0', 'e_t_1', 's_t_0', 's_t_1', 'w_t_0', 'w_t_1']\n",
    "          0          1         2       3         4         5     6        7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd589f1-f522-47a4-ae2c-54afa079185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup\n",
    "option_distributions = []\n",
    "for option in range(0, df_single_episode.option.max() + 1):\n",
    "    dist = get_action_dist(agent, state, option)[0]\n",
    "    for i, value in enumerate(dist):\n",
    "        dist_dict = {\n",
    "            'option': option\n",
    "        }\n",
    "        dist_dict[f'action'] = i\n",
    "        dist_dict[f'prob'] = value\n",
    "        option_distributions.append(dist_dict)\n",
    "df_option_distributions = pd.DataFrame(option_distributions)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for key, grp in df_option_distributions.groupby(['option']):\n",
    "    key = key[0]\n",
    "    ax = grp.plot(ax=ax, kind='line', x='action', y='prob', label=key)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cca06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d99d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea014f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
